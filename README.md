# ğŸ¤– COMPLICE Assistant Multimodal Bienveillant pour Jeunes Autistes

Complice â€” Un compagnon pour comprendre, ressentir et prendre confiance

## ğŸ§  Objectif du projet

Ce projet vise Ã  crÃ©er un assistant conversationnel intelligent, combinant :
- ğŸ” Recherche sÃ©mantique dans une base documentaire sur lâ€™autisme
- ğŸ’¬ Dialogue bienveillant pour sâ€™exercer aux habiletÃ©s sociales
- ğŸ–¼ï¸ GÃ©nÃ©ration dâ€™images de visages exprimant des Ã©motions pour lâ€™apprentissage Ã©motionnel

Lâ€™objectif est de proposer un outil accessible, rassurant et Ã©ducatif pour les jeunes autistes en quÃªte de comprÃ©hension et dâ€™autonomie.

ğŸ§‘â€ğŸ« Ce projet est rÃ©alisÃ© dans le cadre de la formation Data Science Full Stack chez JEDHA comme le projet final pour la certification de "Concepteur DÃ©veloppeur en Science de DonnÃ©es".

---

## ğŸ‘¥ Ã‰quipe

    | PrÃ©nom    | RÃ´le principal                     |Contributions                                            |
    |--------   |----------------                    |----------------                                         |
    | LÃ©a       | Extraction & annotation des donnÃ©es| PDF â†’ texte, chunking, mÃ©tadonnÃ©es, prompts Ã©motionnels |
    | Alisson   | Embeddings & base vectorielle      | Choix du modÃ¨le, FAISS, intÃ©gration LangChain           |
    | AgnÃ¨s     | LLM & gÃ©nÃ©ration de rÃ©ponses       | API LLM, prompts bienveillants, validation UX           |
    | Ludo      | Interface & sÃ©curitÃ©               | Streamlit, intÃ©gration image, filtres de contenu        |

---

## ğŸ—‚ï¸ Structure du projet

    complice/
        â”œâ”€â”€ data/                  # Textes extraits, chunks, embeddings, index FAISS
        â”‚   â”œâ”€â”€ pdf_books/          # (non versionnÃ©) PDF sources originaux
        â”‚   â”œâ”€â”€ extracted_texts/   # (non versionnÃ©) textes extraits
        â”‚   â”œâ”€â”€ ready_for_embedding/  # chunks, chunks avec metadonnÃ©es    
        â”‚   â””â”€â”€ embeddings/         # fichiers .npy, .pkl, .idx
        â”œâ”€â”€ notebooks/             # Notebooks 01 Ã  05 (pipeline RAG)
        â”‚   â”œâ”€â”€ 01_extraction.ipynb # extraction des textes
        â”‚   â”œâ”€â”€ 02_chunking_metadata.ipynb # dÃ©coupage + annotation
        â”‚   â”œâ”€â”€ 03_embeddings.ipynb # gÃ©nÃ©ration des vecteurs
        â”‚   â”œâ”€â”€ 04_indexation_faiss.ipynb # crÃ©ation du vectorstore (.faiss + .pkl)   
        â”‚   â”œâ”€â”€ 05_rag_pipeline.ipynb # requÃªtes RAG avec GPT-4o
        â”‚   â””â”€â”€ 06_validation_rag.ipynb # boucle de questions test et Ã©valuation RAGAS
        â”‚
        â”œâ”€â”€ .gitignore                   # Fichiers Ã  exclure du suivi Git
        â”œâ”€â”€ .dockerignore               # Fichiers Ã  exclure du conteneur Docker
        â”œâ”€â”€ Dockerfile                  # Image Docker pour environnement Jupyter
        â”œâ”€â”€ start.sh                    # Script de lancement du conteneur Docker
        â”œâ”€â”€ requirements.txt            # DÃ©pendances Python du projet
        â””â”€â”€ README.md                   # PrÃ©sentation et documentation du projet


---

### ğŸ”§ Technologies utilisÃ©es

#### ğŸ“š Extraction & prÃ©paration des donnÃ©es
- PyMuPDF, pdfminer.six : extraction de texte depuis PDF
- pandas, numpy, tqdm : manipulation et nettoyage des donnÃ©es

#### ğŸ§  Recherche sÃ©mantique & gÃ©nÃ©ration
- LangChain : orchestration du pipeline RAG
- FAISS : base vectorielle pour la recherche
- sentence-transformers : embeddings multilingues
- OpenAI API : gÃ©nÃ©ration de rÃ©ponses bienveillantes

#### ğŸ§ª Validation & Ã©valuation
- RAGAS : Ã©valuation de la pertinence, fidÃ©litÃ© et bienveillance des rÃ©ponses

#### ğŸ’» Interface & expÃ©rience utilisateur
- Jupyter Notebook : environnement de dÃ©veloppement
- Streamlit / Gradio (*Ã  suivre) : interface utilisateur interactive

#### ğŸ³ DÃ©ploiement & portabilitÃ©
- Docker : conteneurisation pour faciliter lâ€™installation
- python-dotenv : gestion sÃ©curisÃ©e des clÃ©s API

#### ğŸ¤ Collaboration & versioning
- Git / GitHub : gestion du code en Ã©quipe


---

## ğŸ“š Sources documentaires

Les textes utilisÃ©s sont des ouvrages Ã©ducatifs sur lâ€™autisme, lâ€™adolescence et les habiletÃ©s sociales. Tous les documents sont lÃ©galement accessibles et utilisÃ©s dans un cadre non-commercial et pÃ©dagogique.

---

## ğŸ§ª FonctionnalitÃ©s principales

- ğŸ” **Recherche intelligente** : Lâ€™utilisateur peut poser des questions sur lâ€™autisme, les Ã©motions, les relations socialesâ€¦
- ğŸ’¬ **Chat bienveillant** : Dialogue rassurant, adaptÃ© au niveau de comprÃ©hension
- ğŸ–¼ï¸ **Images Ã©motionnelles** : GÃ©nÃ©ration de visages exprimant des Ã©motions (joie, colÃ¨re, tristesse, etc.)
- ğŸ›¡ï¸ **SÃ©curitÃ© & Ã©thique** : Filtrage des rÃ©ponses, personnalisation du ton et du niveau de difficultÃ©

---

## ğŸ“… Planning de rÃ©alisation

| Semaine | Objectifs |
|--------|-----------|
| Semaine 1 | Extraction des donnÃ©es + cadrage technique |
| Semaine 2 | Construction du pipeline RAG |
| Semaine 3 | GÃ©nÃ©ration dâ€™images + interface |
| Semaine 4 | Finalisation + documentation + soutenance |

---
## ğŸ³ Lancer le projet avec Docker

1. Installez Docker sur votre machine.
2. Clonez le dÃ©pÃ´t :
      ```bash
   git clone https://github.com/AgaHei/Complice.git
   cd Complice
3. CrÃ©ez un fichier .env Ã  la racine (OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx)
4. Lancez le conteneur :
    bash start.sh
5. Ouvrez JupyterLab dans votre navigateur : http://localhost:8888 Utilisez le token affichÃ© dans le terminal pour vous connecter.

ğŸ“˜ Les notebooks principaux :

03_embeddings.ipynb â†’ gÃ©nÃ©ration des vecteurs

04_indexation_faiss.ipynb â†’ crÃ©ation du vectorstore

05_rag_pipeline.ipynb â†’ requÃªtes RAG + validation

ğŸ“š Extraction optionnelle : Si vous souhaitez enrichir la base documentaire avec de nouveaux PDF :

01_extraction.ipynb â†’ extraction des textes

02_chunking_metadata.ipynb â†’ dÃ©coupage + annotation


# Lancer l'application (*Ã  suivre)
streamlit run app/main.py

---
## ğŸ¤ Contribuer

Les coÃ©quipiers peuvent :

- Ajouter de nouveaux textes sources (PDF Ã©ducatifs, guides, etc.)
- Proposer des amÃ©liorations aux prompts pour plus de nuance
- Tester des variantes de modÃ¨les (GPT-3.5, GPT-4o, Mistralâ€¦)
- CrÃ©er une interface utilisateur (Streamlit, Gradio)
- Ajouter des filtres thÃ©matiques ou des scores de pertinence

### ğŸ§ª Bonnes pratiques

- Documenter chaque Ã©tape dans les notebooks
- Utiliser des noms de fichiers explicites et versionnÃ©s
- Respecter la philosophie de *Complice* : bienveillance, clartÃ©, inclusion
- Ne jamais exposer de clÃ© API dans le code ou les notebooks


