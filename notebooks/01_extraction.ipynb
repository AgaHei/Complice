{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bac7e721",
   "metadata": {},
   "source": [
    "# üìò Extraction du texte des fichiers PDF avec source et nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa712928",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.98it/s]\n"
     ]
    }
   ],
   "source": [
    "# Importer les biblioth√®ques n√©cessaires\n",
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# üìÅ Dossiers\n",
    "pdf_folder = \"../data/pdf_books\"\n",
    "output_folder = \"../data/extracted_texts\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# üìÑ Fonction d'extraction\n",
    "def extract_text_from_pdf(pdf_path, source_name):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text_chunks = []\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        text = page.get_text(\"text\").strip()\n",
    "        if text:  # Ignore les pages vides\n",
    "            text_chunks.append({\n",
    "                \"source\": source_name,\n",
    "                \"page\": page_num + 1,\n",
    "                \"text\": text\n",
    "            })\n",
    "    return pd.DataFrame(text_chunks)\n",
    "\n",
    "# üîÅ Boucle sur tous les PDF\n",
    "for filename in tqdm(os.listdir(pdf_folder)):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        full_path = os.path.join(pdf_folder, filename)\n",
    "        source_name = filename.replace(\".pdf\", \"\")\n",
    "        df = extract_text_from_pdf(full_path, source_name)\n",
    "        # Sauvegarde en CSV\n",
    "        csv_name = source_name + \".csv\"\n",
    "        df.to_csv(os.path.join(output_folder, csv_name), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c9d0b4",
   "metadata": {},
   "source": [
    "# üßº Pr√©traitement avant l‚Äôembedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca6268e",
   "metadata": {},
   "source": [
    "1. Nettoyage du texte :\n",
    "    - supprimer les caract√®res sp√©ciaux, sauts de page, num√©ros de page, titres r√©p√©titifs\n",
    "    - uniformiser les espaces et ponctuations\n",
    "    - supprimer les lignes trop courtes ou non informatives (ex. : ‚ÄúChapitre 1‚Äù, ‚ÄúPage 12‚Äù)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff6ca39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"\\n+\", \" \", text)  # remplace les sauts de ligne\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)  # supprime les espaces multiples\n",
    "    text = re.sub(r\"Page \\d+\", \"\", text)  # supprime les mentions de page\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af8b34a",
   "metadata": {},
   "source": [
    "2. Chunking intelligent:\n",
    "    - diviser les textes en blocs coh√©rents (‚âà 100‚Äì300 mots)\n",
    "    - utiliser les sauts de paragraphe ou la ponctuation comme rep√®res\n",
    "    - ajouter des m√©tadonn√©es : source, num√©ro de chunk, page d‚Äôorigine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3e712af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, max_words=200):\n",
    "    sentences = re.split(r'(?<=[.!?]) +', text)\n",
    "    chunks, current_chunk = [], []\n",
    "    word_count = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        words = sentence.split()\n",
    "        word_count += len(words)\n",
    "        current_chunk.append(sentence)\n",
    "        if word_count >= max_words:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk, word_count = [], 0\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "    return chunks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7456303",
   "metadata": {},
   "source": [
    "3. Structuration finale - cr√©er un DataFrame avec les colonnes :\n",
    "    - source\n",
    "    - page\n",
    "    - chunk_id\n",
    "    - text_clean\n",
    "    - text_chunked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac73edf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chunks = []\n",
    "\n",
    "for file in os.listdir(\"../data/extracted_texts\"):\n",
    "    if file.endswith(\".csv\"):\n",
    "        df = pd.read_csv(f\"../data/extracted_texts/{file}\")\n",
    "        source = file.replace(\".csv\", \"\")\n",
    "        for _, row in df.iterrows():\n",
    "            cleaned = clean_text(row[\"text\"])\n",
    "            chunks = chunk_text(cleaned)\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                all_chunks.append({\n",
    "                    \"source\": source,\n",
    "                    \"page\": row[\"page\"],\n",
    "                    \"chunk_id\": f\"{source}_p{row['page']}_c{i}\",\n",
    "                    \"text\": chunk\n",
    "                })\n",
    "\n",
    "df_chunks = pd.DataFrame(all_chunks)\n",
    "df_chunks.to_csv(\"../data/ready_for_embedding/chunks.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec26b679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de chunks cr√©√©s : 3316\n"
     ]
    }
   ],
   "source": [
    "# V√©rifier le nombre de chunks cr√©√©s\n",
    "print(f\"Nombre total de chunks cr√©√©s : {len(df_chunks)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
